var documenterSearchIndex = {"docs":
[{"location":"functions/#SCARGC-1","page":"Functions","title":"SCARGC","text":"","category":"section"},{"location":"functions/#","page":"Functions","title":"Functions","text":"Here are some functions in SCARGC module.","category":"page"},{"location":"functions/#","page":"Functions","title":"Functions","text":"SCARGC","category":"page"},{"location":"functions/#SCARGC","page":"Functions","title":"SCARGC","text":"Main module for SCARGC.jl, the Julia implementation of SCARGC algorithm.\n\nFrom this module, two functions are exported for public use:\n\nscargc_1NN. The 1-Nearest Neighbor SCARGC implementation.\nextractValuesFromFile. A functio to extract the data values from a dataset file.\n\n\n\n\n\n","category":"module"},{"location":"functions/#Predicting-functions-1","page":"Functions","title":"Predicting functions","text":"","category":"section"},{"location":"functions/#","page":"Functions","title":"Functions","text":"scargc_1NN","category":"page"},{"location":"functions/#SCARGC.scargc_1NN","page":"Functions","title":"SCARGC.scargc_1NN","text":"scargc_1NN(\n    dataset         -> \"dataset used in the algorighm\"\n    percentTraining -> \"amount of data that is goung to be used as training data\"\n    maxPoolSize     -> \"maximum instances that the pool size can store\"\n    K               -> \"number of clusters\"\n)\n\nSCARGC implementation with the Nearest Neighbor classifier for label predicting. The function prints the final accuracy and returns the vector with all predicted labels and the final accuracy.\n\nThe function starts getting the labeled and unlabeled and, with them, it creates the initial centroids. Then, a loop starts over the unlabeled data, storing the instance and the predicted label (predicted with the classification model). \n\nWhen the pool reaches the maximum, represented by maxPoolSize, a clustering step is made on the data stored in the pool to get the centroids from the current iteration (represented as tempCurrentCentroids before receiving the labels and currentCentroids after it). With the centroids from the past iteration (represented  as centroids), we find the current iteration's centroids' labels and create the intermediary centroids, represented as intermed, that stores the median between the past and current centroids and the current iretation's centroid's labels (the reason to store that is to store the drift between the past and the current iteration).\n\nAfter getting the labels, the past iteration's centroids receive the values stored in intermed and a new labels are found using both centroids from current and past iterations. These labels are going to be useful to get the concordance between them and the labels stored in the pool to know if the model is going to be updated. The last part, after calculating the concordance, is update the classification model if the concordance is different of  100%.\n\nFor example, let's predict some data in the 1CHT dataset.\n\nWe start loading the dataset and reading the values from it.\n\nusing SCARGC\n\n# loading dataset\ndataset = \"datasets/synthetic/1CHT.txt\"\n\n# extracting values from the dataset file and storing into `data`\ndata = extractValuesFromFile(dataset, 16000, 3)\n\n# printing the read dataset\nprinln(data)\n\n# predicting labels and storing them in `predictedLabels` and the accuracy in `accuracy`\npredictedLabels, accuracy = scargc_1NN(data, 0.3125, 300, 2)\n\nIf we print the results, we're gonna have\n\n# predicted labels\n11000-element Array{Int64,1}:\n 1\n 2\n 1\n 1\n 1\n 2\n 1\n 1\n ⋮\n 2\n 1\n 2\n 1\n 2\n 2\n 2\n\n# accuracy ~\n99.73040752351096\n\nThe accuracy happens if you're using a dataset with the actual labels of all instances. Then the function can compare the prediction with the actual label to get the accuracy.\n\n\n\n\n\n","category":"function"},{"location":"functions/#Utilities-1","page":"Functions","title":"Utilities","text":"","category":"section"},{"location":"functions/#","page":"Functions","title":"Functions","text":"extractValuesFromFile","category":"page"},{"location":"functions/#SCARGC.extractValuesFromFile","page":"Functions","title":"SCARGC.extractValuesFromFile","text":"extractValuesFromFile(\n    fileName -> \"name of the file that you're trying to read\"\n    rows     -> \"number of rows in the file\"\n    columns  -> \"number of columns in the file\"\n)\n\nThe function reads a file and creates a matrix with the file's values. Using the function readuntil and parse we can converte each value, separeted by comma.\n\nThe function returns a matrix with the values in the file.\n\nFor example, let's suppose we have a text file, called \"example.txt\", with 10 lines and 7 columns.\n\n2.91120, 2.94941, 2.92468, 0.88324, 6.00512, 5.88021, 3\n4.97443, 2.31345, 5.21826, 8.13938, 7.47390, 8.24444, 1\n3.13772, 7.87192, 8.35722, 7.41002, 6.95894, 5.20002, 2\n3.74301, 6.39082, 3.89166, 8.76716, 1.66374, 6.75246, 3\n8.98766, 4.42780, 4.94278, 7.05217, 5.21106, 3.69790, 1\n4.38337, 4.91497, 6.16593, 8.73148, 6.17557, 0.90185, 2\n0.97263, 2.70122, 0.00343, 7.20105, 1.63296, 8.26112, 1\n0.50329, 3.54209, 8.47787, 2.59826, 3.93825, 2.58200, 3\n6.75223, 4.59601, 2.02472, 8.10523, 3.65602, 6.91874, 1\n8.98924, 2.33177, 8.34892, 4.03544, 8.57646, 7.93690, 1\n\nWe're gonna run this function with the following values:\n\nfileName is going to receive the path to the file. In this case, it's just \"example.txt\";\nrows is going to receive 10 and\ncolumns is going to receive 7\n\nThen, the function starts and reads each value separated by \",\" and stores these values into  a matrix. This matrix is returned in the end of the function, in the format:\n\n10×7 Array{Float64,2}:\n2.91120, 2.94941, 2.92468, 0.88324, 6.00512, 5.88021, 3\n4.97443, 2.31345, 5.21826, 8.13938, 7.47390, 8.24444, 1\n3.13772, 7.87192, 8.35722, 7.41002, 6.95894, 5.20002, 2\n3.74301, 6.39082, 3.89166, 8.76716, 1.66374, 6.75246, 3\n8.98766, 4.42780, 4.94278, 7.05217, 5.21106, 3.69790, 1\n4.38337, 4.91497, 6.16593, 8.73148, 6.17557, 0.90185, 2\n0.97263, 2.70122, 0.00343, 7.20105, 1.63296, 8.26112, 1\n0.50329, 3.54209, 8.47787, 2.59826, 3.93825, 2.58200, 3\n6.75223, 4.59601, 2.02472, 8.10523, 3.65602, 6.91874, 1\n8.98924, 2.33177, 8.34892, 4.03544, 8.57646, 7.93690, 1\n\nThis matrix is then ready to be used along the code.\n\n\n\n\n\n","category":"function"},{"location":"#SCARGC.jl-1","page":"Home","title":"SCARGC.jl","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"A Julia Implementation of Stream Classification Algorithm Guidded by Clustering","category":"page"},{"location":"#","page":"Home","title":"Home","text":"(Image: Build Status) (Image: Coverage Status) (Image: License File)","category":"page"},{"location":"#","page":"Home","title":"Home","text":"SCARGC.jl is a Julia implementation  of Stream Classification Algorithm Guided by Clustering - SCARGC -, a data stream  classifier in non-stationary environments with extreme verification latency. The  implementation was made using the paper as base and the official implementation  of SCARGC, in MatLab.","category":"page"},{"location":"#Overview-1","page":"Home","title":"Overview","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Most of research data on data stream classification with concept drift, assumes  that there's a availability of the labels, instantly or with some delay after  the classification occurs. Then, these methods verify if the model is outdated based on the classification information obtained on the recent data.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"SCARGC.jl is an algorithm that make predictions with a EVL scenary, where no labeled data is received after the  initialization of the model. So, for example, we receive a small amount of labeled data, build a classifier model with this data and, after that, there's no labeled data \"arriving\". We just predict and update the model to get a better result in the next iteration.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"note: Note\nThe package is still under development, so keep your version updated to get the newests features and don't miss anything.","category":"page"},{"location":"#Installation-1","page":"Home","title":"Installation","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"In the Julia's package manager, type:","category":"page"},{"location":"#","page":"Home","title":"Home","text":"pkg> add SCARGC","category":"page"},{"location":"#Tutorials-1","page":"Home","title":"Tutorials","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"You can find some notebooks explaining how to use the package in  experiments.","category":"page"},{"location":"#Quick-example-1","page":"Home","title":"Quick example","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"We can see below a example of using the SCARGC.jl package to predict labels in datasets.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"note: Note\nIt's important to say that the dataset used in the example is a synthetic  dataset, so we already have the instances's label. Using it, we can say the accuracy of the algorithm. If you're using it with some real application,  with no data, the accuracy calculus isn't going to happen.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"using SCARGC\r\n\r\n# loading the dataset\r\ndataset = \"../../src/datasets/synthetic/1CHT.txt\"\r\ndata = SCARGC.extractValuesFromFile(dataset, 16000, 3)\r\n\r\n# predicting data\r\nlabels, accuracy = SCARGC.scargc_1NN(data, 0.3125, 300, 2)\r\n\r\n# then, we can print the accuracy\r\nprintln(\"Accuracy: \", accuracy, \"%\")","category":"page"},{"location":"#Results-1","page":"Home","title":"Results","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Today, the results of SCARGC.jl are equivalent to the first implemented, in MatLab.","category":"page"},{"location":"#","page":"Home","title":"Home","text":"In the picture below, the blue bars represent the original SCARGC and the black ones represent SCARGC.jl results on those datasets (represented in X asis).","category":"page"},{"location":"#","page":"Home","title":"Home","text":"(Image: Result)","category":"page"},{"location":"#References-1","page":"Home","title":"References","text":"","category":"section"},{"location":"#","page":"Home","title":"Home","text":"Souza, V. M. A.; Silva, D. F.; Gama, J.; Batista, G. E. A. P. A.: Data Stream Classification Guided by Clustering on Nonstationary Environments and Extreme Verification Latency. SIAM International Conference on Data Mining (SDM), pp. 873-881, 2015","category":"page"}]
}
